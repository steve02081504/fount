// 导入 Anthropic SDK 和 Fount 需要的工具函数
import Anthropic from 'npm:@anthropic-ai/sdk'
import { escapeRegExp } from '../../../../src/scripts/escape.mjs'
import { margeStructPromptChatLog, structPromptToSingleNoChatLog } from '../../shells/chat/src/server/prompt_struct.mjs'
import * as mime from 'npm:mime-types'
// 导入 undici 用于设置代理
import * as undici from 'npm:undici'

/** @typedef {import('../../../decl/AIsource.ts').AIsource_t} AIsource_t */
/** @typedef {import('../../../decl/prompt_struct.ts').prompt_struct_t} prompt_struct_t */

// Claude 支持的图片 MIME 类型
const supportedImageTypes = [
	'image/jpeg',
	'image/png',
	'image/gif',
	'image/webp',
]

export default {
	interfaces: {
		AIsource: {
			GetConfigTemplate: async () => configTemplate,
			GetSource,
		}
	}
}

// Claude 模块的默认配置模板
const configTemplate = {
	name: 'claude-3.5-sonnet',
	apikey: '',
	model: 'claude-3-5-sonnet-20240620',
	model_arguments: {
	},
	proxy_url: '', // 例如 'http://127.0.0.1:7890'
	use_stream: true,
}

async function GetSource(config) {
	// 初始化 Anthropic 客户端
	const clientOptions = {
		apiKey: config.apikey,
	}

	// 如果配置了代理 URL，则设置代理
	if (config.proxy_url)
		clientOptions.fetchOptions = {
			dispatcher: new undici.ProxyAgent(config.proxy_url),
		}

	const client = new Anthropic(clientOptions)

	/** @type {AIsource_t} */
	const result = {
		type: 'text-chat',
		info: {
			'': {
				avatar: '', // 可在此处放置头像 URL
				name: config.name || config.model,
				provider: 'Anthropic',
				description: 'Anthropic Claude',
				description_markdown: '由 Anthropic 公司开发的 Claude 模型。',
				version: '0.0.1',
				author: 'Generated by AI',
				homepage: 'https://www.anthropic.com/',
				tags: ['Anthropic', 'Claude'],
			}
		},
		is_paid: true,
		extension: {},

		Unload: () => { },

		// 简单的文本调用
		Call: async (prompt) => {
			const params = {
				model: config.model,
				messages: [{ role: 'user', content: prompt }],
				...config.model_arguments,
			}

			let text = ''

			if (config.use_stream) {
				const stream = await client.messages.create({ ...params, stream: true })
				for await (const event of stream)
					if (event.type === 'content_block_delta' && event.delta.type === 'text_delta')
						text += event.delta.text


			} else {
				const message = await client.messages.create(params)
				// Claude 的响应 content 是一个数组，我们只取文本部分
				text = message.content.filter(block => block.type === 'text').map(block => block.text).join('')
			}

			return {
				content: text,
			}
		},

		// 结构化的多模态调用
		StructCall: async (/** @type {prompt_struct_t} */ prompt_struct) => {
			// 使用 Fount 工具函数获取独立的系统提示
			const system_prompt = structPromptToSingleNoChatLog(prompt_struct)

			// 使用 Fount 工具函数合并聊天记录，并转换为 Claude 的格式
			const messages = await Promise.all(margeStructPromptChatLog(prompt_struct).map(async (chatLogEntry) => {
				const role = chatLogEntry.role === 'user' || chatLogEntry.role === 'system' ? 'user' : 'assistant'

				// 内容可以是文本和图片的混合数组
				const content = []

				// 添加文本内容
				content.push({
					type: 'text',
					text: chatLogEntry.name + ':\n' + chatLogEntry.content,
				})

				// 处理并添加文件内容（仅限图片）
				if (chatLogEntry.files)
					for (const file of chatLogEntry.files) {
						const mimeType = file.mimeType || mime.lookup(file.name) || 'application/octet-stream'
						if (supportedImageTypes.includes(mimeType))
							try {
								content.push({
									type: 'image',
									source: {
										type: 'base64',
										media_type: mimeType,
										data: file.buffer.toString('base64'),
									}
								})
							} catch (error) {
								console.error(`Failed to process image file ${file.name}:`, error)
								// 如果处理失败，可以添加一条错误信息文本
								content.push({
									type: 'text',
									text: `[System Error: Failed to process image file ${file.name}]`,
								})
							}
						 else {
							console.warn(`Unsupported file type for Claude: ${mimeType} for file ${file.name}. Skipping.`)
							content.push({
								type: 'text',
								text: `[System Info: File ${file.name} with type ${mimeType} was skipped as it is not a supported image format.]`
							})
						}
					}


				return { role, content }
			}))

			// 构建最终的 API 请求参数
			const params = {
				model: config.model,
				system: system_prompt,
				messages,
				...config.model_arguments,
			}

			let text = ''
			const files = [] // 用于存放模型生成的图片（如果未来支持）

			if (config.use_stream) {
				const stream = await client.messages.create({ ...params, stream: true })
				for await (const event of stream)
					if (event.type === 'content_block_delta' && event.delta.type === 'text_delta')
						text += event.delta.text


			} else {
				const message = await client.messages.create(params)
				text = message.content.filter(block => block.type === 'text').map(block => block.text).join('')
			}

			// --- 复用 Gemini 模块的响应清理逻辑，以保证行为一致 ---
			{
				text = text.split('\n')
				const base_reg = `^((|${[...new Set([
					prompt_struct.Charname,
					...prompt_struct.chat_log.map((chatLogEntry) => chatLogEntry.name),
				])].filter(Boolean).map(escapeRegExp).concat([
					...(prompt_struct.alternative_charnames || []).map(Object).map(
						(stringOrReg) => {
							if (stringOrReg instanceof String) return escapeRegExp(stringOrReg)
							return stringOrReg.source
						}
					),
				].filter(Boolean)).join('|')})[^\\n：:\<\>\\d\`]*)(:|：)\\s*(?!\/)`
				let reg = new RegExp(`${base_reg}$`, 'i')
				while (text.length > 0 && text[0].trim().match(reg)) text.shift()
				reg = new RegExp(`${base_reg}`, 'i')
				if (text.length > 0)
					text[0] = text[0].replace(reg, '')

				while (text.length > 0 && text[text.length - 1].trim() === '') text.pop()
				text = text.join('\n')
			}

			return {
				content: text,
				files,
			}
		},
		Tokenizer: {
			free: () => 0,
			encode: (prompt) => prompt,
			decode: (tokens) => tokens,
			decode_single: (token) => token,
			get_token_count: (prompt) => typeof prompt === 'string' ? prompt.length : 0,
		}
	}

	return result
}
