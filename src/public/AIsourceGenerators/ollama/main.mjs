import fs from 'node:fs'
import path from 'node:path'

import { Ollama } from 'npm:ollama'

import { margeStructPromptChatLog, structPromptToSingleNoChatLog } from '../../shells/chat/src/prompt_struct.mjs'

/** @typedef {import('../../../decl/AIsource.ts').AIsource_t} AIsource_t */
/** @typedef {import('../../../decl/prompt_struct.ts').prompt_struct_t} prompt_struct_t */

/**
 * @type {import('../../../decl/AIsource.ts').AIsource_interfaces_and_AIsource_t_getter}
 */
export default {
	info: {
		'en-UK': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Run large language models locally.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'local', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'zh-CN': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'åœ¨æœ¬åœ°è¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ã€‚',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'æœ¬åœ°', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'ar-SA': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù„ØºÙˆÙŠØ© ÙƒØ¨ÙŠØ±Ø© Ù…Ø­Ù„ÙŠÙ‹Ø§.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'Ù…Ø­Ù„ÙŠ', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'de-DE': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'FÃ¼hren Sie groÃŸe Sprachmodelle lokal aus.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'lokal', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		emoji: {
			name: 'ğŸ¦™',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Run large language models locally.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'local', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'es-ES': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Ejecute grandes modelos de lenguaje localmente.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'local', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'fr-FR': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'ExÃ©cutez de grands modÃ¨les de langage localement.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'local', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'hi-IN': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'à¤“à¤²à¤¾à¤®à¤¾',
			description_markdown: 'à¤¬à¤¡à¤¼à¥‡ à¤­à¤¾à¤·à¤¾ à¤®à¥‰à¤¡à¤² à¤•à¥‹ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤°à¥‚à¤ª à¤¸à¥‡ à¤šà¤²à¤¾à¤à¤‚à¥¤',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['à¤“à¤²à¤¾à¤®à¤¾', 'à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯', 'à¤à¤²à¤à¤²à¤à¤®'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'is-IS': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Keyra stÃ³r tungumÃ¡lalÃ­kÃ¶n Ã¡ staÃ°num.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'staÃ°bundiÃ°', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'it-IT': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Esegui grandi modelli linguistici in locale.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'locale', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'ja-JP': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œã—ã¾ã™ã€‚',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'ãƒ­ãƒ¼ã‚«ãƒ«', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'ko-KR': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'ì˜¬ë¼ë§ˆ',
			description_markdown: 'ë¡œì»¬ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ì˜¬ë¼ë§ˆ', 'ë¡œì»¬', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		lzh: {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'æ–¼æœ¬åœ°é‹è¡Œå¤§å‹èªè¨€æ¨¡å‹ã€‚',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'æœ¬åœ°', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'nl-NL': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Voer grote taalmodellen lokaal uit.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'lokaal', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'pt-PT': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Execute grandes modelos de linguagem localmente.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'local', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'ru-RU': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ğ¹Ñ‚Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'uk-UA': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ğ¹Ñ‚Ğµ Ğ²ĞµĞ»Ğ¸ĞºÑ– Ğ¼Ğ¾Ğ²Ğ½Ñ– Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'vi-VN': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'Cháº¡y cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n cá»¥c bá»™.',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'cá»¥c bá»™', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		},
		'zh-TW': {
			name: 'Ollama',
			avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
			description: 'Ollama',
			description_markdown: 'åœ¨æœ¬åœ°é‹è¡Œå¤§å‹èªè¨€æ¨¡å‹ã€‚',
			version: '0.0.1',
			author: 'steve02081504',
			tags: ['ollama', 'æœ¬åœ°', 'llm'],
			home_page: 'https://ollama.com/',
			provider: 'Ollama'
		}
	},
	interfaces: {
		AIsource: {
			/**
			 * è·å–æ­¤ AI æºçš„é…ç½®æ˜¾ç¤ºå†…å®¹ã€‚
			 * @returns {Promise<object>} é…ç½®æ˜¾ç¤ºå†…å®¹ã€‚
			 */
			GetConfigDisplayContent: async () => ({
				js: fs.readFileSync(path.join(import.meta.dirname, 'display.mjs'), 'utf-8')
			}),
			/**
			 * è·å–æ­¤ AI æºçš„é…ç½®æ¨¡æ¿ã€‚
			 * @returns {Promise<object>} é…ç½®æ¨¡æ¿ã€‚
			 */
			GetConfigTemplate: async () => configTemplate,
			GetSource,
		}
	}
}

const configTemplate = {
	name: 'ollama',
	host: 'http://127.0.0.1:11434',
	model: 'llama3',
	model_arguments: {
		temperature: 1,
		num_predict: -1, // -1 for infinite
	},
	system_prompt_at_depth: 10,
	convert_config: {
		roleReminding: true
	}
}

/**
 * è·å– AI æºã€‚
 * @param {object} config - é…ç½®å¯¹è±¡ã€‚
 * @returns {Promise<AIsource_t>} AI æºã€‚
 */
async function GetSource(config) {
	const ollama = new Ollama({ host: config.host })

	/** @type {AIsource_t} */
	const result = {
		type: 'text-chat',
		info: {
			'en-UK': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Run large language models locally.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'local', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'zh-CN': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'åœ¨æœ¬åœ°è¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ã€‚',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'æœ¬åœ°', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'ar-SA': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù„ØºÙˆÙŠØ© ÙƒØ¨ÙŠØ±Ø© Ù…Ø­Ù„ÙŠÙ‹Ø§.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'Ù…Ø­Ù„ÙŠ', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'de-DE': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'FÃ¼hren Sie groÃŸe Sprachmodelle lokal aus.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'lokal', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			emoji: {
				name: 'ğŸ¦™',
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Run large language models locally.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'local', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'es-ES': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Ejecute grandes modelos de lenguaje localmente.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'local', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'fr-FR': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'ExÃ©cutez de grands modÃ¨les de langage localement.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'local', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'hi-IN': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'à¤“à¤²à¤¾à¤®à¤¾',
				description_markdown: 'à¤¬à¤¡à¤¼à¥‡ à¤­à¤¾à¤·à¤¾ à¤®à¥‰à¤¡à¤² à¤•à¥‹ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤°à¥‚à¤ª à¤¸à¥‡ à¤šà¤²à¤¾à¤à¤‚à¥¤',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['à¤“à¤²à¤¾à¤®à¤¾', 'à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯', 'à¤à¤²à¤à¤²à¤à¤®'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'is-IS': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Keyra stÃ³r tungumÃ¡lalÃ­kÃ¶n Ã¡ staÃ°num.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'staÃ°bundiÃ°', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'it-IT': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Esegui grandi modelli linguistici in locale.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'locale', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'ja-JP': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œã—ã¾ã™ã€‚',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'ãƒ­ãƒ¼ã‚«ãƒ«', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'ko-KR': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'ì˜¬ë¼ë§ˆ',
				description_markdown: 'ë¡œì»¬ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ì˜¬ë¼ë§ˆ', 'ë¡œì»¬', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			lzh: {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'æ–¼æœ¬åœ°é‹è¡Œå¤§å‹èªè¨€æ¨¡å‹ã€‚',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'æœ¬åœ°', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'nl-NL': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Voer grote taalmodellen lokaal uit.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'lokaal', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'pt-PT': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Execute grandes modelos de linguagem localmente.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'local', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'ru-RU': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ğ¹Ñ‚Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'uk-UA': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ğ¹Ñ‚Ğµ Ğ²ĞµĞ»Ğ¸ĞºÑ– Ğ¼Ğ¾Ğ²Ğ½Ñ– Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'vi-VN': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'Cháº¡y cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n cá»¥c bá»™.',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'cá»¥c bá»™', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			},
			'zh-TW': {
				name: config.name || config.model,
				avatar: 'https://api.iconify.design/simple-icons/ollama.svg',
				description: 'Ollama',
				description_markdown: 'åœ¨æœ¬åœ°é‹è¡Œå¤§å‹èªè¨€æ¨¡å‹ã€‚',
				version: '0.0.1',
				author: 'steve02081504',
				tags: ['ollama', 'æœ¬åœ°', 'llm'],
				home_page: 'https://ollama.com/',
				provider: 'Ollama'
			}
		},
		is_paid: false,
		extension: {},

		/**
		 * è°ƒç”¨ AI æºã€‚
		 * @param {string} prompt - è¦å‘é€ç»™ AI çš„æç¤ºã€‚
		 * @returns {Promise<{content: string}>} æ¥è‡ª AI çš„ç»“æœã€‚
		 */
		Call: async prompt => {
			const response = await ollama.generate({
				model: config.model,
				prompt,
				stream: false,
				options: config.model_arguments
			})
			return {
				content: response.response,
			}
		},
		/**
		 * ä½¿ç”¨ç»“æ„åŒ–æç¤ºè°ƒç”¨ AI æºã€‚
		 * @param {prompt_struct_t} prompt_struct - è¦å‘é€ç»™ AI çš„ç»“æ„åŒ–æç¤ºã€‚
		 * @returns {Promise<{content: string, files: any[]}>} æ¥è‡ª AI çš„ç»“æœã€‚
		 */
		StructCall: async (/** @type {prompt_struct_t} */ prompt_struct) => {
			const messages = margeStructPromptChatLog(prompt_struct).map(chatLogEntry => {
				const images = (chatLogEntry.files || [])
					.filter(file => file.mime_type && file.mime_type.startsWith('image/'))
					.map(file => file.buffer.toString('base64'))

				/** @type {{role: 'user'|'assistant'|'system', content: string, images?: string[]}} */
				const message = {
					role: chatLogEntry.role === 'user' ? 'user' : chatLogEntry.role === 'system' ? 'system' : 'assistant',
					content: chatLogEntry.content,
				}
				if (images.length) message.images = images

				return message
			})

			const system_prompt = structPromptToSingleNoChatLog(prompt_struct)
			if (system_prompt) {
				const systemMessage = {
					role: 'system',
					content: system_prompt
				}
				if (config.system_prompt_at_depth && config.system_prompt_at_depth < messages.length)
					messages.splice(Math.max(messages.length - config.system_prompt_at_depth, 0), 0, systemMessage)
				else
					messages.unshift(systemMessage)

			}


			if (config.convert_config?.roleReminding ?? true) {
				const isMutiChar = new Set(prompt_struct.chat_log.map(chatLogEntry => chatLogEntry.name).filter(Boolean)).size > 2
				if (isMutiChar)
					messages.push({
						role: 'system',
						content: `Now, please continue the conversation as ${prompt_struct.Charname}.`
					})
			}

			let response_text = ''
			const response_files = []

			const response = await ollama.chat({
				model: config.model,
				messages,
				stream: false,
				options: config.model_arguments
			})
			response_text = response.message.content

			return {
				content: response_text,
				files: response_files
			}
		},
		tokenizer: {
			/**
			 * é‡Šæ”¾åˆ†è¯å™¨ã€‚
			 * @param {any} _ - æœªä½¿ç”¨ã€‚
			 * @returns {number} 0
			 */
			free: _ => 0,
			/**
			 * ç¼–ç æç¤ºã€‚
			 * @param {string} prompt - è¦ç¼–ç çš„æç¤ºã€‚
			 * @returns {string} ç¼–ç åçš„æç¤ºã€‚
			 */
			encode: prompt => prompt,
			/**
			 * è§£ç ä»¤ç‰Œã€‚
			 * @param {string} tokens - è¦è§£ç çš„ä»¤ç‰Œã€‚
			 * @returns {string} è§£ç åçš„ä»¤ç‰Œã€‚
			 */
			decode: tokens => tokens,
			/**
			 * è§£ç å•ä¸ªä»¤ç‰Œã€‚
			 * @param {string} token - è¦è§£ç çš„ä»¤ç‰Œã€‚
			 * @returns {string} è§£ç åçš„ä»¤ç‰Œã€‚
			 */
			decode_single: token => token,
			/**
			 * è·å–ä»¤ç‰Œè®¡æ•°ã€‚
			 * @param {string} prompt - è¦è®¡ç®—ä»¤ç‰Œçš„æç¤ºã€‚
			 * @returns {Promise<number>} ä»¤ç‰Œæ•°ã€‚
			 */
			get_token_count: async prompt => {
				if (!prompt) return 0
				try {
					const response = await ollama.encode({ model: config.model, prompt })
					return response.tokens.length
				}
				catch (error) {
					console.warn('Failed to get token count from Ollama API, falling back to character count.', error)
					return (prompt?.length ?? 0) / 4
				}
			}
		}
	}
	return result
}
